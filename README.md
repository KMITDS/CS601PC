# CS601PC
#MACHINE LEARNING
#III Year B.Tech. CSE II-Sem 
#Course Objectives
1. This course explains machine learning techniques such as decision tree learning, Bayesian 
learning etc.
2. To understand computational learning theory.
3. To study the pattern comparison techniques.
Course Outcomes
1. Understand the concepts of computational intelligence like machine learning 
2. Ability to get the skill to apply machine learning techniques to address the real time problems 
in different areas
3. Understand the Neural Networks and its usage in machine learning application.
UNIT - I 
Introduction - Well-posed learning problems, designing a learning system, Perspectives and issues in 
machine learning
Concept learning and the general to specific ordering – introduction, a concept learning task, concept 
learning as search, find-S: finding a maximally specific hypothesis, version spaces and the candidate 
elimination algorithm, remarks on version spaces and candidate elimination, inductive bias.
Decision Tree Learning – Introduction, decision tree representation, appropriate problems for decision 
tree learning, the basic decision tree learning algorithm, hypothesis space search in decision tree 
learning, inductive bias in decision tree learning, issues in decision tree learning.
UNIT - II
Artificial Neural Networks-1– Introduction, neural network representation, appropriate problems for 
neural network learning, perceptions, multilayer networks and the back-propagation algorithm.
Artificial Neural Networks-2- Remarks on the Back-Propagation algorithm, An illustrative example: 
face recognition, advanced topics in artificial neural networks.
Evaluation Hypotheses – Motivation, estimation hypothesis accuracy, basics of sampling theory, a 
general approach for deriving confidence intervals, difference in error of two hypotheses, comparing
learning algorithms.
UNIT - III
Bayesian learning – Introduction, Bayes theorem, Bayes theorem and concept learning, Maximum 
Likelihood and least squared error hypotheses, maximum likelihood hypotheses for predicting 
probabilities, minimum description length principle, Bayes optimal classifier, Gibs algorithm, Naïve
Bayes classifier, an example: learning to classify text, Bayesian belief networks, the EM algorithm.
Computational learning theory – Introduction, probably learning an approximately correct hypothesis, 
sample complexity for finite hypothesis space, sample complexity for infinite hypothesis spaces, the 
mistake bound model of learning.
Instance-Based Learning- Introduction, k-nearest neighbour algorithm, locally weighted regression, 
radial basis functions, case-based reasoning, remarks on lazy and eager learning.
UNIT- IV
Genetic Algorithms – Motivation, Genetic algorithms, an illustrative example, hypothesis space 
search, genetic programming, models of evolution and learning, parallelizing genetic algorithms.
Learning Sets of Rules – Introduction, sequential covering algorithms, learning rule sets: summary, 
learning First-Order rules, learning sets of First-Order rules: FOIL, Induction as inverted deduction, 
inverting resolution.
Reinforcement Learning – Introduction, the learning task, Q–learning, non-deterministic, rewards and 
actions, temporal difference learning, generalizing from examples, relationship to dynamic 
programming.
UNIT - V
Analytical Learning-1- Introduction, learning with perfect domain theories: PROLOG-EBG, remarks 
on explanation-based learning, explanation-based learning of search control knowledge.
Analytical Learning-2-Using prior knowledge to alter the search objective, using prior knowledge to 
augment search operators. 
Combining Inductive and Analytical Learning – Motivation, inductive-analytical approaches to 
learning, using prior knowledge to initialize the hypothesis.
TEXT BOOKS:
1. Machine Learning – Tom M. Mitchell, - MGH
REFERENCES:
1. Machine Learning: An Algorithmic Perspective, Stephen Marshland, Taylor & Francis 
